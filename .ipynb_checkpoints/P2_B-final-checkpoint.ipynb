{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd =  os.getcwd()\n",
    "inputfile = open(cwd+'/Brown_tagged_train.txt','r')\n",
    "brown = inputfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tags = []\n",
    "brown_words = []\n",
    "for sentence in brown:\n",
    "    words = sentence.strip().split()\n",
    "    list_tag = []\n",
    "    for wordtag in words:\n",
    "        tag = wordtag.rsplit('/',1)[-1]\n",
    "        list_tag.append(tag)\n",
    "    brown_tags.append(list_tag)\n",
    "\n",
    "for sentence in brown:\n",
    "    words = sentence.strip().split()\n",
    "    list_word = []\n",
    "    for wordtag in words:\n",
    "        word = wordtag.rsplit('/',1)[0]\n",
    "        list_word.append(word)\n",
    "    brown_words.append(list_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_count = dict()\n",
    "bigram_count = dict()\n",
    "trigram_count = dict()\n",
    "for sent_words in brown_words:\n",
    "    uni = sent_words[2:]\n",
    "    unigrams_words = [tuple(uni[i:(i+1)]) for i in range(len(uni)-1+1)]\n",
    "    for unigram in unigrams_words:\n",
    "        if unigram not in unigram_count:\n",
    "            unigram_count[unigram] = 0\n",
    "        unigram_count[unigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['.','ADJ','ADP','ADV','CONJ','DET','NOUN','NUM','PRON','PRT','VERB','X']\n",
    "#get_bin = lambda x: format(x, 'b').zfill(4)\n",
    "binary = dict()\n",
    "for i in range(len(classes)):\n",
    "    if classes[i] not in binary.keys():\n",
    "        binary[classes[i]] = 0\n",
    "    binary[classes[i]] = i+1\n",
    "#binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "features_of_word = dict()\n",
    "for i in range(len(brown_words)):\n",
    "    for j in range(len(brown_words[i])):\n",
    "        word = brown_words[i][j]\n",
    "        current_word = brown_words[i][j]\n",
    "  \n",
    "        features_of_word = {\n",
    "                        'word'              :unigram_count[current_word] if current_word in unigram_count else 0,\n",
    "                        'prefix'            :ord(current_word[0]),\n",
    "                        'suffix'            :ord(current_word[-1]),\n",
    "                        'prev-word'         : -1 if j == 0 else unigram_count[brown_words[i][j-1]] if brown_words[i][j-1] in unigram_count else 0,\n",
    "                        '2-prev-word'       : -1 if j <= 1 else unigram_count[brown_words[i][j-2]] if brown_words[i][j-2] in unigram_count else 0,\n",
    "                        'next-word'         : -1 if j >= len(brown_words[i]) - 1     else unigram_count[brown_words[i][j + 1]] if brown_words[i][j+1] in unigram_count else 0,\n",
    "                        '2-next-word'       : -1 if j >= len(brown_words[i]) - 2     else unigram_count[brown_words[i][j + 2]] if brown_words[i][j+2] in unigram_count else 0,\n",
    "                        'is_first'          : 1 if j == 0  else 0,\n",
    "                        'is_last'           : 1 if j == len(brown_words[i])-1  else 0,\n",
    "                        'is_capitalized'    : 1 if word[0].upper() == word[0]  else 0,\n",
    "                        'is_all_capitalized': 1 if word.upper() == word else 0,\n",
    "                        'is_capitals_inside': 1 if word[1:].lower() != word[1:]   else 0,\n",
    "                        'is_numeric'        : 1 if word.isdigit()   else 0,\n",
    "                       }\n",
    "        features.append(features_of_word)\n",
    "        labels.append(brown_tags[i][j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd =  os.getcwd()\n",
    "inputfile = open(cwd+'/Brown_dev.txt','r')\n",
    "brown_dev_tags = [['PRON','VERB','VERB','CONJ','VERB','DET','NOUN','NOUN','VERB','DET','NOUN']]\n",
    "brown_dev = []\n",
    "brown1 = inputfile.readlines()\n",
    "for sentence in brown1:\n",
    "    words = sentence.strip().split()\n",
    "    list_word = []\n",
    "    for wordtag in words:\n",
    "        list_word.append(wordtag)\n",
    "    brown_dev.append(list_word)\n",
    "test_labels = []\n",
    "# print(brown_dev)\n",
    "\n",
    "unigram_count_dev = dict()\n",
    "for sent_words in brown_dev:\n",
    "    uni = sent_words[2:]\n",
    "    unigrams_words = [tuple(uni[i:(i+1)]) for i in range(len(uni)-1+1)]\n",
    "    for unigram in unigrams_words:\n",
    "        if unigram not in unigram_count_dev:\n",
    "            unigram_count_dev[unigram] = 0\n",
    "        unigram_count_dev[unigram] += 1\n",
    "\n",
    "\n",
    "features1 = []\n",
    "features_of_word = dict()\n",
    "for i in range(len(brown_dev)):\n",
    "    for j in range(len(brown_dev[i])):\n",
    "        word = brown_dev[i][j]\n",
    "        current_word = brown_dev[i][j]\n",
    "  \n",
    "        features1_of_word = {\n",
    "                        'word'              :unigram_count_dev[current_word] if current_word in unigram_count_dev else 0,\n",
    "                        'prefix'            :ord(current_word[0]),\n",
    "                        'suffix'            :ord(current_word[-1]),\n",
    "                        'prev-word'         : -1 if j == 0 else unigram_count_dev[brown_dev[i][j-1]] if brown_dev[i][j-1] in unigram_count_dev else 0,\n",
    "                        '2-prev-word'       : -1 if j <= 1 else unigram_count_dev[brown_dev[i][j-2]] if brown_dev[i][j-2] in unigram_count_dev else 0,\n",
    "                        'next-word'         : -1 if j >= len(brown_dev[i]) - 1     else unigram_count_dev[brown_dev[i][j + 1]] if brown_dev[i][j+1] in unigram_count_dev else 0,\n",
    "                        '2-next-word'       : -1 if j >= len(brown_dev[i]) - 2     else unigram_count_dev[brown_dev[i][j + 2]] if brown_dev[i][j+2] in unigram_count_dev else 0,\n",
    "                        'is_first'          : 1 if j == 0  else 0,\n",
    "                        'is_last'           : 1 if j == len(brown_dev[i])-1  else 0,\n",
    "                        'is_capitalized'    : 1 if word[0].upper() == word[0]  else 0,\n",
    "                        'is_all_capitalized': 1 if word.upper() == word else 0,\n",
    "                        'is_capitals_inside': 1 if word[1:].lower() != word[1:]   else 0,\n",
    "                        'is_numeric'        : 1 if word.isdigit()   else 0,\n",
    "                       }\n",
    "        features1.append(features1_of_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features)\n",
    "tf = pd.DataFrame(features1)\n",
    "X,Y = df.shape\n",
    "X1,Y1 = tf.shape\n",
    "b = np.ones((X,1))\n",
    "df = np.hstack((df,b))\n",
    "b = np.ones((X1,1))\n",
    "tf = np.hstack((tf,b))\n",
    "num_features = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovish/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/lovish/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(df,axis=0)\n",
    "stdev = np.std(df,axis=0,ddof=1)\n",
    "df = (df - mean)/stdev\n",
    "tf = (tf-mean)/stdev\n",
    "for i in range(len(tf)):\n",
    "    for j in range(len(tf[i])):\n",
    "        if math.isnan(tf[i][j]):\n",
    "            tf[i][j] = 0.0\n",
    "        tf[i][13] = 1\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df[i])):\n",
    "        if math.isnan(df[i][j]):\n",
    "            df[i][j] = 0.0\n",
    "        df[i][13] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_grad(W, X, y, reg):\n",
    "    W = np.array(W)\n",
    "    W = W.reshape(1,num_features+1)\n",
    "    dim, num_train = X.shape\n",
    "    grad = np.zeros_like(W)\n",
    "    f_x_mat = W.dot(X)\n",
    "    h_x_mat = 1.0 / (1.0 + np.exp(-f_x_mat))\n",
    "    grad = (h_x_mat - y).dot(X.T)\n",
    "    grad = 1.0 / num_train * grad\n",
    "    W -= lr * grad \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.randn(12 , num_features+1) *0.001\n",
    "W = np.array(W)\n",
    "lr = 1e-4\n",
    "num_iters = 1000\n",
    "reg = 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_iter = 0\n",
    "for c in binary.keys():\n",
    "    X_Train = []\n",
    "    Y_Train = []\n",
    "    for it in range(len(df)):\n",
    "        if labels[it]==c:\n",
    "            X_Train.append(df[it])\n",
    "            Y_Train.append(1)\n",
    "        else:\n",
    "            X_Train.append(df[it])\n",
    "            Y_Train.append(0)\n",
    "    X_Train = np.array(X_Train).T\n",
    "    for i in range(0,num_iters):\n",
    "        W[class_iter]= loss_grad(W[class_iter],X_Train,np.array(Y_Train),reg)\n",
    "    class_iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, X):\n",
    "    scores = []\n",
    "    for i in range(0,12):\n",
    "        W[i] = np.array(W[i]).reshape(1,num_features+1)\n",
    "        scores.append(W[i].dot(X))\n",
    "    ind = (scores.index(max(scores)))\n",
    "    #print(scores)\n",
    "    return ind    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "VERB\n",
      "NOUN\n",
      "NOUN\n",
      "NOUN\n",
      "NOUN\n",
      "NOUN\n",
      "NOUN\n",
      "NOUN\n",
      "NOUN\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i in range(len(tf)):\n",
    "    print(classes[predict(W,tf[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
